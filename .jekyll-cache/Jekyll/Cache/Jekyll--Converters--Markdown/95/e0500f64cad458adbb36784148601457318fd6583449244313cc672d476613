I"<h2 id="理论知识">理论知识</h2>

<h3 id="bagging基于数据随机重抽样的分类器构建方法">bagging：基于数据随机重抽样的分类器构建方法</h3>

<p>自举汇聚法(bootsrap aggregating)也称为bagging方法：通过从原始数据集选择S次后得到S个新数据集的一种技术，<strong>新数据集和原数据集大小相等</strong>，每个数据集由原始数据集中<strong>有放回</strong>的随机抽取的数据。将某个学习算法分别作用于S个数据集得到S个分类器，当对新数据进行分类时就使用这S个分类器对数据进行分类。</p>

<h3 id="bossting">bossting</h3>

<p>boosting与bagging很相似，但是bagging中不同的分类器通过串行训练获得。每个新分类器都根据已经训练出的<strong>分类器的性能</strong>来进行训练，而boosting通过关注被已有分类器<strong>错分的数据</strong>来获得新分类器。bagging中的分类器权重相等，boosting中的分类器权重不等，每个权重代表对应分类器在上一轮迭代中的成功度。</p>

<h2 id="训练算法基于错误提升分类器的性能">训练算法：基于错误提升分类器的性能</h2>

<p>AdaBoost是adaptive boosting的缩写。算法运行过程中：每个训练样本被赋予一个相等的初始权重，每次训练完成后分错的样本的权重将会提高，分对的样本的权重降低，且每个分类器也有根据其分类错误率计算出的权值alpha。</p>

<p>错误率：<img src="http://latex.codecogs.com/gif.latex?%5Cvarepsilon%20%3D%20%5Cfrac%7Bnum%5C_of%5C_wrong%7D%7Ball%7D" /><br />
alpha: <img src="http://latex.codecogs.com/gif.latex?%5Calpha%20%3D%20%5Cfrac%7B1%7D%7B2%7D%20%5Cln%5Cleft%28%5Cfrac%7B1-%5Cvarepsilon%7D%7B%5Cvarepsilon%7D%20%5Cright%29" /><br />
分对的样本权重向量D: <img src="http://latex.codecogs.com/gif.latex?D%5E%28t&plus;1%29_i%20%3D%20%5Cfrac%7BD%5E%7B%28t%29%7D_ie%5E%7B-%5Calpha%7D%7D%7BSum%28D%29%7D" /><br />
分错的样本权重向量D: <img src="http://latex.codecogs.com/gif.latex?D%5E%28t&plus;1%29_i%20%3D%20%5Cfrac%7BD%5E%7B%28t%29%7D_ie%5E%7B%5Calpha%7D%7D%7BSum%28D%29%7D" /></p>

<h2 id="基于单层决策树构建弱分类器">基于单层决策树构建弱分类器</h2>

<p>单层决策树仅基于单个特征来做决策，只有一次分裂过程</p>

<h3 id="准备数据">准备数据</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">loadSimpData</span><span class="p">():</span>
    <span class="n">dataMat</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mat</span><span class="p">([</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.1</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s">'float'</span><span class="p">)</span>
    <span class="n">classLabels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mat</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s">'int'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dataMat</span><span class="p">,</span> <span class="n">classLabels</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dataMat</span><span class="p">,</span> <span class="n">classLabels</span> <span class="o">=</span> <span class="n">loadSimpData</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="单层决策树生成函数">单层决策树生成函数</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">stumpClassify</span><span class="p">(</span><span class="n">dataMatrix</span><span class="p">,</span> <span class="n">dimen</span><span class="p">,</span> <span class="n">threshVal</span><span class="p">,</span> <span class="n">threshIneq</span><span class="p">):</span>
    <span class="s">"""
    通过阈值比较对数据进行分类
    dataMat: 数据集
    dimen: 要比较的目标列索引
    threshVal: 阈值
    threshIneq: 分类结果设置方式，若为'lt'则将所有小于等于阈值的值置-1，否则将所有大于阈值的值置-1
    """</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="n">dataMatrix</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">threshIneq</span> <span class="o">==</span> <span class="s">'lt'</span><span class="p">:</span>
        <span class="n">result</span><span class="p">[</span><span class="n">dataMatrix</span><span class="p">[:,</span><span class="n">dimen</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">threshVal</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">result</span><span class="p">[</span><span class="n">dataMatrix</span><span class="p">[:,</span><span class="n">dimen</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">threshVal</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span>
    <span class="k">return</span> <span class="n">result</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">buildStump</span><span class="p">(</span><span class="n">dataMat</span><span class="p">,</span> <span class="n">classLabels</span><span class="p">,</span> <span class="n">D</span><span class="p">):</span>
    <span class="s">"""
    遍历单层决策树的参数可能取值，构建多个决策树，根据分类结果返回最佳的决策树相关信息
    dataMat: 数据集
    classLabels: 数据集标签
    D: 权重向量
    """</span>
    <span class="n">labelMat</span> <span class="o">=</span> <span class="n">classLabels</span><span class="p">.</span><span class="n">T</span>
    <span class="n">numSteps</span> <span class="o">=</span> <span class="mi">10</span>  <span class="c1"># 步数
</span>    <span class="n">bestStump</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># 分类性能最佳时的参数
</span>    <span class="n">bestClassEst</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mat</span><span class="p">((</span><span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">dataMat</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">))))</span>  <span class="c1"># 分类性能最佳时预测结果
</span>    <span class="n">minError</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">inf</span>  <span class="c1"># 最小错误率，初始时为无穷大
</span>    <span class="c1"># 遍历所有特征
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dataMat</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">rangeMin</span> <span class="o">=</span> <span class="n">dataMat</span><span class="p">[:,</span><span class="n">i</span><span class="p">].</span><span class="nb">min</span><span class="p">()</span>  <span class="c1"># 数据集第i个特征最小值
</span>        <span class="n">rangeMax</span> <span class="o">=</span> <span class="n">dataMat</span><span class="p">[:,</span><span class="n">i</span><span class="p">].</span><span class="nb">max</span><span class="p">()</span>  <span class="c1"># 数据集第i个特征最大值
</span>        <span class="n">stepSize</span> <span class="o">=</span> <span class="p">(</span><span class="n">rangeMax</span> <span class="o">-</span> <span class="n">rangeMin</span><span class="p">)</span> <span class="o">/</span> <span class="n">numSteps</span>  <span class="c1"># 每一步的大小
</span>        <span class="c1"># 遍历所有阈值
</span>        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">numSteps</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="c1"># 遍历每种分类方式
</span>            <span class="k">for</span> <span class="n">inequal</span> <span class="ow">in</span> <span class="p">[</span><span class="s">'lt'</span><span class="p">,</span><span class="s">'gt'</span><span class="p">]:</span>
                <span class="n">threshVal</span> <span class="o">=</span> <span class="n">rangeMin</span> <span class="o">+</span> <span class="n">j</span> <span class="o">*</span> <span class="n">stepSize</span>  <span class="c1"># 根据步数计算阈值
</span>                <span class="n">predictedVals</span> <span class="o">=</span> <span class="n">stumpClassify</span><span class="p">(</span><span class="n">dataMat</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">threshVal</span><span class="p">,</span> <span class="n">inequal</span><span class="p">)</span>
                <span class="n">errArr</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mat</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="n">dataMat</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)))</span>  <span class="c1"># 分类错误的数据
</span>                <span class="n">errArr</span><span class="p">[</span><span class="n">predictedVals</span> <span class="o">==</span> <span class="n">labelMat</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># 分类正确置0，错误置1
</span>                <span class="n">weightedError</span> <span class="o">=</span> <span class="n">D</span><span class="p">.</span><span class="n">T</span> <span class="o">*</span> <span class="n">errArr</span>  <span class="c1"># 计算加权错误率(利用矩阵相乘代替求和)
</span>                <span class="k">if</span> <span class="n">weightedError</span> <span class="o">&lt;</span> <span class="n">minError</span><span class="p">:</span>
                    <span class="n">minError</span> <span class="o">=</span> <span class="n">weightedError</span>
                    <span class="n">bestClassEst</span> <span class="o">=</span> <span class="n">predictedVals</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
                    <span class="n">bestStump</span><span class="p">[</span><span class="s">'dim'</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
                    <span class="n">bestStump</span><span class="p">[</span><span class="s">'thresh'</span><span class="p">]</span> <span class="o">=</span> <span class="n">threshVal</span>
                    <span class="n">bestStump</span><span class="p">[</span><span class="s">'ineq'</span><span class="p">]</span> <span class="o">=</span> <span class="n">inequal</span>
    <span class="k">return</span> <span class="n">bestStump</span><span class="p">,</span> <span class="n">minError</span><span class="p">,</span> <span class="n">bestClassEst</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mat</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span><span class="o">/</span><span class="mi">5</span><span class="p">)</span>
<span class="n">buildStump</span><span class="p">(</span><span class="n">dataMat</span><span class="p">,</span> <span class="n">classLabels</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>({'dim': 0, 'thresh': 0.9, 'ineq': 'lt'}, matrix([[0.]]), array([[1.],
        [1.],
        [1.],
        [1.],
        [1.]]))
</code></pre></div></div>

<h2 id="完整adaboost算法实现">完整AdaBoost算法实现</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">adaBoostTrainDS</span><span class="p">(</span><span class="n">dataArr</span><span class="p">,</span> <span class="n">classLabels</span><span class="p">,</span> <span class="n">numIt</span><span class="o">=</span><span class="mi">40</span><span class="p">):</span>
    <span class="n">weakClassArr</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># 存储所有弱分类器的参数
</span>    <span class="n">m</span> <span class="o">=</span> <span class="n">dataArr</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mat</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span><span class="o">/</span><span class="n">m</span><span class="p">)</span>  <span class="c1"># 数据初始权重
</span>    <span class="n">aggClassEst</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mat</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numIt</span><span class="p">):</span>
        <span class="c1"># 构建单个决策树
</span>        <span class="n">bestStump</span><span class="p">,</span> <span class="n">error</span><span class="p">,</span> <span class="n">classEst</span> <span class="o">=</span> <span class="n">buildStump</span><span class="p">(</span><span class="n">dataArr</span><span class="p">,</span> <span class="n">classLabels</span><span class="p">,</span> <span class="n">D</span><span class="p">)</span>
        <span class="c1">#print("D:", D.T)
</span>        <span class="n">alpha</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">((</span><span class="mi">1</span><span class="o">-</span><span class="n">error</span><span class="p">)</span><span class="o">/</span><span class="nb">max</span><span class="p">(</span><span class="n">error</span><span class="p">,</span><span class="mf">1e-16</span><span class="p">)))</span>  <span class="c1"># 根据公式计算α，分母为max(error, 1e-16)是为了防止分母为0
</span>        <span class="n">bestStump</span><span class="p">[</span><span class="s">'alpha'</span><span class="p">]</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="n">weakClassArr</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">bestStump</span><span class="p">)</span>  <span class="c1"># 将训练好的弱分类器添加入分类器列表
</span>        <span class="c1">#print("classEst: ", classEst.T)
</span>        <span class="c1"># 更新D
</span>        <span class="n">tmp</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">multiply</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">alpha</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">mat</span><span class="p">(</span><span class="n">classLabels</span><span class="p">).</span><span class="n">T</span><span class="p">,</span><span class="n">classEst</span><span class="p">)</span>
        <span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">D</span><span class="p">,</span><span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="n">tmp</span><span class="p">))</span>
        <span class="n">D</span> <span class="o">=</span> <span class="n">D</span> <span class="o">/</span> <span class="n">D</span><span class="p">.</span><span class="nb">sum</span><span class="p">()</span>
        <span class="c1"># 计算错误率
</span>        <span class="n">aggClassEst</span> <span class="o">+=</span> <span class="n">classEst</span> <span class="o">*</span> <span class="n">alpha</span>
        <span class="c1">#print("aggC;assEst: ", aggClassEst.T)
</span>        <span class="c1">#aggErrors = (aggClassEst.T != classLabels).sum()
</span>        <span class="n">aggErrors</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">multiply</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">sign</span><span class="p">(</span><span class="n">aggClassEst</span><span class="p">)</span> <span class="o">!=</span> <span class="n">np</span><span class="p">.</span><span class="n">mat</span><span class="p">(</span><span class="n">classLabels</span><span class="p">).</span><span class="n">T</span><span class="p">,</span><span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>
        <span class="n">errorRate</span> <span class="o">=</span> <span class="n">aggErrors</span><span class="p">.</span><span class="nb">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">dataArr</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"total error: "</span><span class="p">,</span> <span class="n">errorRate</span><span class="p">)</span>
        <span class="c1"># 错误率为0时提前终止
</span>        <span class="k">if</span> <span class="n">errorRate</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">break</span>
    <span class="k">return</span> <span class="n">weakClassArr</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">adaBoostTrainDS</span><span class="p">(</span><span class="n">dataMat</span><span class="p">,</span> <span class="n">classLabels</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>total error:  0.2
total error:  0.2
total error:  0.0





[{'dim': 0, 'thresh': 1.3, 'ineq': 'lt', 'alpha': 0.6931471805599453},
 {'dim': 1, 'thresh': 1.0, 'ineq': 'lt', 'alpha': 0.9729550745276565},
 {'dim': 0, 'thresh': 0.9, 'ineq': 'lt', 'alpha': 0.8958797346140273}]
</code></pre></div></div>

<h2 id="测试算法基于adaboost的分类">测试算法：基于AdaBoost的分类</h2>

<h3 id="adaboost分类函数">AdaBoost分类函数</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">adaClassify</span><span class="p">(</span><span class="n">dataMat</span><span class="p">,</span> <span class="n">classifierArr</span><span class="p">):</span>
    <span class="n">aggClassEst</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mat</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">dataMat</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">classifierArr</span><span class="p">)):</span>
        <span class="n">classEst</span> <span class="o">=</span> <span class="n">stumpClassify</span><span class="p">(</span><span class="n">dataMat</span><span class="p">,</span><span class="n">classifierArr</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s">'dim'</span><span class="p">],</span><span class="n">classifierArr</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s">'thresh'</span><span class="p">],</span><span class="n">classifierArr</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s">'ineq'</span><span class="p">])</span>
        <span class="n">aggClassEst</span> <span class="o">+=</span> <span class="n">classifierArr</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s">'alpha'</span><span class="p">]</span> <span class="o">*</span> <span class="n">classEst</span>
        <span class="c1">#print(aggClassEst)
</span>    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">sign</span><span class="p">(</span><span class="n">aggClassEst</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">classifierArr</span> <span class="o">=</span> <span class="n">adaBoostTrainDS</span><span class="p">(</span><span class="n">dataMat</span><span class="p">,</span> <span class="n">classLabels</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>total error:  0.2
total error:  0.2
total error:  0.0
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">adaClassify</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mat</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]]),</span> <span class="n">classifierArr</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>matrix([[ 1.],
        [-1.]])
</code></pre></div></div>

<h2 id="示例在一个难数据集上应用adaboost">示例：在一个难数据集上应用AdaBoost</h2>

<h3 id="加载数据">加载数据</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">loadDataSet</span><span class="p">(</span><span class="n">fileName</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fileName</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">f</span><span class="p">.</span><span class="n">readlines</span><span class="p">()</span>
    <span class="n">dataMat</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mat</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">strip</span><span class="p">().</span><span class="n">split</span><span class="p">(</span><span class="s">'</span><span class="se">\t</span><span class="s">'</span><span class="p">))</span><span class="o">-</span><span class="mi">1</span><span class="p">)))</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mat</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="n">strip</span><span class="p">().</span><span class="n">split</span><span class="p">(</span><span class="s">'</span><span class="se">\t</span><span class="s">'</span><span class="p">)</span>
        <span class="n">dataMat</span><span class="p">[</span><span class="n">i</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">tmp</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="s">'float'</span><span class="p">)</span>
        <span class="n">labels</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">tmp</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">dataMat</span><span class="p">,</span> <span class="n">labels</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dataMat</span><span class="p">,</span> <span class="n">labelArr</span> <span class="o">=</span> <span class="n">loadDataSet</span><span class="p">(</span><span class="s">'data/horseColicTraining2.txt'</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="利用adaboost分类">利用AdaBoost分类</h3>

<p>训练分类器</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">classifierArr</span> <span class="o">=</span> <span class="n">adaBoostTrainDS</span><span class="p">(</span><span class="n">dataMat</span><span class="p">,</span> <span class="n">labelArr</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>total error:  0.2842809364548495
total error:  0.2842809364548495
total error:  0.24749163879598662
total error:  0.24749163879598662
total error:  0.25418060200668896
total error:  0.2408026755852843
total error:  0.2408026755852843
total error:  0.22073578595317725
total error:  0.24749163879598662
total error:  0.23076923076923078
</code></pre></div></div>

<p>测试分类器</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">testMat</span><span class="p">,</span> <span class="n">testLabelArr</span> <span class="o">=</span> <span class="n">loadDataSet</span><span class="p">(</span><span class="s">'data/horseColicTest2.txt'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">prediction</span> <span class="o">=</span> <span class="n">adaClassify</span><span class="p">(</span><span class="n">testMat</span><span class="p">,</span> <span class="n">classifierArr</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">errArr</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mat</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">prediction</span><span class="p">))</span>
<span class="n">errArr</span><span class="p">[</span><span class="n">prediction</span><span class="o">!=</span><span class="n">testLabelArr</span><span class="p">.</span><span class="n">T</span><span class="p">].</span><span class="nb">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">errArr</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.23880597014925373
</code></pre></div></div>

<p>可见使用AdaBoost进行分类时错误率为0.2388，比Logitic回归的0.35+的错误率要低</p>
:ET