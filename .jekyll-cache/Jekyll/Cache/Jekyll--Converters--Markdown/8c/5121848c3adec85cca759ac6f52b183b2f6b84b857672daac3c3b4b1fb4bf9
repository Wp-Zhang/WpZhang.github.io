I"ϱ<h2 id="理论部分">理论部分</h2>

<h3 id="基于贝叶斯决策理论的分类方法">基于贝叶斯决策理论的分类方法</h3>

<p><strong>优点</strong>：在数据量较少的情况下仍然有效，可以处理多类别问题</p>

<p><strong>缺点</strong>：对于输入数据的准备方式较为敏感</p>

<p><strong>适用数据类型</strong>：标称型数据</p>

<h3 id="概率公式">概率公式</h3>

<p>条件概率公式：<img src="http://latex.codecogs.com/gif.latex?p%28A%7CB%29%20%3D%20%5Cfrac%7Bp%28AB%29%7D%7Bp%28B%29%7D" />，计算事件B发生的前提下事件A发生的概率</p>

<p>贝叶斯准则：<img src="http://latex.codecogs.com/gif.latex?p%28c%7Cx%29%20%3D%20%5Cfrac%7Bp%28x%7Cc%29%20p%28c%29%7D%7Bp%28x%29%7D" />，在已知<img src="http://latex.codecogs.com/gif.latex?p%28x%7Cc%29" />的情况下计算<img src="http://latex.codecogs.com/gif.latex?p%28c%7Cx%29" /></p>

<h3 id="使用条件概率进行分类">使用条件概率进行分类</h3>

<p>假设要分类的点是(x, y)，现有两个分类<img src="http://latex.codecogs.com/gif.latex?c_1" />和<img src="http://latex.codecogs.com/gif.latex?c_2" />，通过条件概率对这个点进行分类即比较该点可能为每一个类别的概率，出现概率最大的即为该点所属分类，即比较<img src="http://latex.codecogs.com/gif.latex?p%28c_1%7Cx%2C%20y%29" />和<img src="http://latex.codecogs.com/gif.latex?p%28c_2%7Cx%2C%20y%29" />。</p>

<p>可以通过贝叶斯准则计算：<img src="http://latex.codecogs.com/gif.latex?p%28c_i%7Cx%2Cy%29%20%3D%20%5Cfrac%7Bp%28x%2Cy%7Cc_i%29%20p%28c_i%29%7D%7Bp%28x%2Cy%29%7D" /></p>

<p>最终若<img src="http://latex.codecogs.com/gif.latex?p%28c_1%7Cx%2Cy%29%20%3E%20p%28c_2%7Cx%2Cy%29" />，则(x,y)属于<img src="http://latex.codecogs.com/gif.latex?c_1" />, 若<img src="http://latex.codecogs.com/gif.latex?p%28c_1%7Cx%2Cy%29%20%3C%20p%28c_2%7Cx%2Cy%29" />，(x,y)属于<img src="http://latex.codecogs.com/gif.latex?c_2" /></p>

<h3 id="使用朴素贝叶斯进行文档分类">使用朴素贝叶斯进行文档分类</h3>

<p>朴素贝叶斯之所以称为“朴素”，是因为其假设所有特征之间在统计学上是互相独立的（即每个特征的出现与其他特征无关）。虽然这个假设在现实生活中的大多数情况中看起来都不是很合适，但是朴素贝叶斯在实际中的表现却很好。</p>

<h2 id="使用python进行侮辱性文本分类">使用Python进行侮辱性文本分类</h2>

<h3 id="准备数据从文档中构建词向量词集模型">准备数据：从文档中构建词向量–词集模型</h3>

<p>文本分类过程中使用的特征来自于<strong>词条</strong>（字符的任意组合），这里我们吧文本看成单词向量或词条向量（把句子转换为向量）。</p>

<p>具体步骤为：</p>
<ol>
  <li>考虑出现在所有文档中的所有单词，将一些词纳入词汇表/词汇集合；</li>
  <li>将每一篇文章转换为词汇表上的向量</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">loadDataSet</span><span class="p">():</span>
    <span class="n">postingList</span><span class="o">=</span><span class="p">[[</span><span class="s">'my'</span><span class="p">,</span> <span class="s">'dog'</span><span class="p">,</span> <span class="s">'has'</span><span class="p">,</span> <span class="s">'flea'</span><span class="p">,</span> <span class="s">'problems'</span><span class="p">,</span> <span class="s">'help'</span><span class="p">,</span> <span class="s">'please'</span><span class="p">],</span>
                 <span class="p">[</span><span class="s">'maybe'</span><span class="p">,</span> <span class="s">'not'</span><span class="p">,</span> <span class="s">'take'</span><span class="p">,</span> <span class="s">'him'</span><span class="p">,</span> <span class="s">'to'</span><span class="p">,</span> <span class="s">'dog'</span><span class="p">,</span> <span class="s">'park'</span><span class="p">,</span> <span class="s">'stupid'</span><span class="p">],</span>
                 <span class="p">[</span><span class="s">'my'</span><span class="p">,</span> <span class="s">'dalmation'</span><span class="p">,</span> <span class="s">'is'</span><span class="p">,</span> <span class="s">'so'</span><span class="p">,</span> <span class="s">'cute'</span><span class="p">,</span> <span class="s">'I'</span><span class="p">,</span> <span class="s">'love'</span><span class="p">,</span> <span class="s">'him'</span><span class="p">],</span>
                 <span class="p">[</span><span class="s">'stop'</span><span class="p">,</span> <span class="s">'posting'</span><span class="p">,</span> <span class="s">'stupid'</span><span class="p">,</span> <span class="s">'worthless'</span><span class="p">,</span> <span class="s">'garbage'</span><span class="p">],</span>
                 <span class="p">[</span><span class="s">'mr'</span><span class="p">,</span> <span class="s">'licks'</span><span class="p">,</span> <span class="s">'ate'</span><span class="p">,</span> <span class="s">'my'</span><span class="p">,</span> <span class="s">'steak'</span><span class="p">,</span> <span class="s">'how'</span><span class="p">,</span> <span class="s">'to'</span><span class="p">,</span> <span class="s">'stop'</span><span class="p">,</span> <span class="s">'him'</span><span class="p">],</span>
                 <span class="p">[</span><span class="s">'quit'</span><span class="p">,</span> <span class="s">'buying'</span><span class="p">,</span> <span class="s">'worthless'</span><span class="p">,</span> <span class="s">'dog'</span><span class="p">,</span> <span class="s">'food'</span><span class="p">,</span> <span class="s">'stupid'</span><span class="p">]]</span>
    <span class="n">classVec</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>    <span class="c1">#1 is abusive, 0 not
</span>    <span class="k">return</span> <span class="n">postingList</span><span class="p">,</span><span class="n">classVec</span>

<span class="k">def</span> <span class="nf">createVocabList</span><span class="p">(</span><span class="n">dataSet</span><span class="p">):</span>
    <span class="n">vocabSet</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([])</span>  <span class="c1"># 创建一个空词汇集合
</span>    <span class="k">for</span> <span class="n">document</span> <span class="ow">in</span> <span class="n">dataSet</span><span class="p">:</span>
        <span class="n">vocabSet</span> <span class="o">=</span> <span class="n">vocabSet</span> <span class="o">|</span> <span class="nb">set</span><span class="p">(</span><span class="n">document</span><span class="p">)</span>  <span class="c1"># 将文档中每一行的词汇集合与当前词汇集合作并集
</span>    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">vocabSet</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">words2Vec_set</span><span class="p">(</span><span class="n">vocabList</span><span class="p">,</span> <span class="n">inputSet</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">vocabList</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s">'int'</span><span class="p">)</span>  <span class="c1"># 创建一个等长于词汇集合的由0组成的表
</span>    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">inputSet</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">vocabList</span><span class="p">:</span>
            <span class="n">result</span><span class="p">[</span><span class="n">vocabList</span><span class="p">.</span><span class="n">index</span><span class="p">(</span><span class="n">word</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># 若单词出现，则在列表中对应位置将值置1
</span>        <span class="k">else</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="s">"the word %s is not in vocabulary"</span> <span class="o">%</span> <span class="n">word</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span>
</code></pre></div></div>

<p>loadDataSet函数创建了一个数据集合用于测试，createVocabList函数根据数据集创建并返回了一个词汇集合，word2Vec函数根据已有的词汇集合以及输入集合，由单词是否出现构建0-1列表并返回</p>

<h3 id="训练算法从词向量计算概率">训练算法：从词向量计算概率</h3>

<p>下面是朴素贝叶斯分类器训练函数</p>

<p>根据我们已有的数据修改贝叶斯准则：将x,y替换为<strong>w</strong>:  <img src="http://latex.codecogs.com/gif.latex?p%28c_i%7Cw%29%20%3D%20%5Cfrac%7Bp%28w%7Cc_i%29%20p%28c_i%29%7D%7Bp%28w%29%7D" /></p>

<p>这里的<strong>w</strong>指的是一个向量，由多个数值组成。由朴素贝叶斯假设可知，<img src="http://latex.codecogs.com/gif.latex?%24p%28w%7Cc_i%29%20%3D%20%5Cprod%5En_%7Bj%3D1%7Dp%28w_j%7Cc_i%29%24" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">trainNB</span><span class="p">(</span><span class="n">trainMatrix</span><span class="p">,</span> <span class="n">trainCategory</span><span class="p">):</span>
    <span class="s">"""
    trainMatrix: 文档矩阵
    trainCategory: 文档类别标签
    """</span>
    <span class="n">numTrainDocs</span> <span class="o">=</span> <span class="n">trainMatrix</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">numWords</span> <span class="o">=</span> <span class="n">trainMatrix</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">p_c</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">trainCategory</span><span class="p">)</span> <span class="o">/</span> <span class="n">numTrainDocs</span>  <span class="c1"># 计算侮辱性文档在总文档中占比
</span>    <span class="n">p_1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">numWords</span><span class="p">)</span>  <span class="c1"># 统计侮辱性文档中单词出现次数
</span>    <span class="n">p_0</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">ones</span><span class="p">(</span><span class="n">numWords</span><span class="p">)</span>  <span class="c1"># 统计非侮辱性文档中单词出现次数
</span>    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">numTrainDocs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">trainCategory</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">p_1</span> <span class="o">+=</span> <span class="n">trainMatrix</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">p_0</span> <span class="o">+=</span> <span class="n">trainMatrix</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    
    <span class="c1"># 计算p(wj|ci)
</span>    <span class="n">p_1_vec</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">p_1</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">p_1</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># 计算侮辱性文档中单词出现的占比
</span>    <span class="n">p_0_vec</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="n">p_0</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">p_0</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>  <span class="c1"># 计算非侮辱性文档中单词出现的占比
</span>    
    <span class="k">return</span> <span class="n">p_0_vec</span><span class="p">,</span> <span class="n">p_1_vec</span><span class="p">,</span> <span class="n">p_c</span>    
</code></pre></div></div>

<p>trainNB函数返回文档列表中：非侮辱性文档中各单词出现占比，侮辱性文档中各单词出现占比，侮辱性文档在总文档中占比</p>

<p><strong>注意：</strong></p>
<ol>
  <li>在初始化单词出现次数的时候不是生成全0列表，而是全1列表的原因是：避免在之后将所有<img src="http://latex.codecogs.com/gif.latex?p%28w_j%7Cc_i%29" />相乘时由于单一出现概率为0导致最终结果为0的情况</li>
  <li>在最终计算<img src="http://latex.codecogs.com/gif.latex?p%28w_j%7Cc_i%29" />时在分母上+1是为了避免总出现次数为0而导致分母为0无法计算除法的情况</li>
  <li>在最终计算<img src="http://latex.codecogs.com/gif.latex?p%28w_j%7Cc_i%29" />时将整体结果进行对数计算是为了防止多个小概率相乘导致计算结果不精确</li>
</ol>

<p>至此，分类器就已经训练完成了，下面开始测试分类。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">classifyNB</span><span class="p">(</span><span class="n">vec_to_classify</span><span class="p">,</span> <span class="n">p_0_vec</span><span class="p">,</span> <span class="n">p_1_vec</span><span class="p">,</span> <span class="n">p_class_1</span><span class="p">):</span>
    <span class="n">p1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">vec_to_classify</span> <span class="o">*</span> <span class="n">p_1_vec</span><span class="p">)</span> <span class="o">/</span> <span class="n">p_class_1</span>
    <span class="n">p0</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">vec_to_classify</span> <span class="o">*</span> <span class="n">p_0_vec</span><span class="p">)</span> <span class="o">/</span> <span class="n">p_class_1</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">p1</span> <span class="o">&gt;</span> <span class="n">p0</span> <span class="k">else</span> <span class="mi">0</span>
</code></pre></div></div>

<p>classifyNB函数根据贝叶斯准则计算文档属于各分类的概率，进行比较后返回比较结果。</p>

<p>函数中仅计算了<img src="http://latex.codecogs.com/gif.latex?p%28w%7Cc_i%29p%28c_i%29" />而没有计算<img src="http://latex.codecogs.com/gif.latex?%5Cfrac%7Bp%28w%7Cc_i%29p%28c_i%29%7D%7Bp%28w%29%7D" />的原因是要比较的概率都有相同的<img src="http://latex.codecogs.com/gif.latex?p%28w%29" />，此时只用比较分子即可。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">testingNB</span><span class="p">():</span>
    <span class="n">posts</span><span class="p">,</span> <span class="n">class_list</span> <span class="o">=</span> <span class="n">loadDataSet</span><span class="p">()</span>  <span class="c1"># 获取数据集
</span>    <span class="n">vocab_list</span> <span class="o">=</span> <span class="n">createVocabList</span><span class="p">(</span><span class="n">posts</span><span class="p">)</span>  <span class="c1"># 获取词汇集合
</span>    <span class="c1"># 根据词汇集合中的单词是否在文档中出现，将文档列表转化为0-1矩阵
</span>    <span class="n">trainMat</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">posts</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab_list</span><span class="p">)))</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span><span class="n">post</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">posts</span><span class="p">):</span>
        <span class="n">trainMat</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">=</span> <span class="n">words2Vec_set</span><span class="p">(</span><span class="n">vocab_list</span><span class="p">,</span> <span class="n">post</span><span class="p">)</span>
    <span class="c1"># 获取训练集中的信息
</span>    <span class="n">p0_vec</span><span class="p">,</span> <span class="n">p1_vec</span><span class="p">,</span> <span class="n">pAbusive</span> <span class="o">=</span> <span class="n">trainNB</span><span class="p">(</span><span class="n">trainMat</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">class_list</span><span class="p">))</span>
    
    <span class="c1"># 准备测试集1
</span>    <span class="n">test</span> <span class="o">=</span> <span class="p">[</span><span class="s">'love'</span><span class="p">,</span> <span class="s">'my'</span><span class="p">,</span> <span class="s">'dalmation'</span><span class="p">]</span>
    <span class="n">test_doc</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">words2Vec_set</span><span class="p">(</span><span class="n">vocab_list</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
    <span class="c1"># 分类
</span>    <span class="k">print</span><span class="p">(</span><span class="s">"'"</span><span class="o">+</span><span class="s">' '</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">test</span><span class="p">)</span><span class="o">+</span><span class="s">"'"</span><span class="p">,</span><span class="s">"classified as :"</span><span class="p">,</span> <span class="n">classifyNB</span><span class="p">(</span><span class="n">test_doc</span><span class="p">,</span> <span class="n">p0_vec</span><span class="p">,</span> <span class="n">p1_vec</span><span class="p">,</span> <span class="n">pAbusive</span><span class="p">))</span>
    <span class="c1"># 准备测试集2
</span>    <span class="n">test</span> <span class="o">=</span> <span class="p">[</span><span class="s">'stupid'</span><span class="p">,</span><span class="s">'garbage'</span><span class="p">]</span>
    <span class="n">test_doc</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">words2Vec_set</span><span class="p">(</span><span class="n">vocab_list</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
    <span class="c1"># 分类
</span>    <span class="k">print</span><span class="p">(</span><span class="s">"'"</span><span class="o">+</span><span class="s">' '</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">test</span><span class="p">)</span><span class="o">+</span><span class="s">"'"</span><span class="p">,</span><span class="s">"classified as :"</span><span class="p">,</span> <span class="n">classifyNB</span><span class="p">(</span><span class="n">test_doc</span><span class="p">,</span> <span class="n">p0_vec</span><span class="p">,</span> <span class="n">p1_vec</span><span class="p">,</span> <span class="n">pAbusive</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">testingNB</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>'love my dalmation' classified as : 0
'stupid garbage' classified as : 1
</code></pre></div></div>

<p>testingNB函数中封装了一次完整的文档分类流程：准备训练集，训练分类器，准备测试集，进行分类</p>

<h3 id="准备数据文档词袋模型">准备数据：文档词袋模型</h3>

<p>之前使用的<strong>词集模型</strong>将每个词的出现与否作为一个特征，如果某个词在文档中出现不止一次，则意味着该词出现的次数可能包含了一些该词出现与否所没有的隐含信息，这就是词袋模型。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">words2Vec_bag</span><span class="p">(</span><span class="n">vocabList</span><span class="p">,</span> <span class="n">inputSet</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocabList</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">inputSet</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">vocabList</span><span class="p">:</span>
            <span class="n">result</span><span class="p">[</span><span class="n">vocabList</span><span class="p">.</span><span class="n">index</span><span class="p">(</span><span class="n">word</span><span class="p">)]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">result</span>
</code></pre></div></div>

<p>words2Vec_bag函数中将原来的<code class="language-plaintext highlighter-rouge">result[vocabList.index(word)] = 1</code>改为了<code class="language-plaintext highlighter-rouge">result[vocabList.index(word)] += 1</code></p>

<h2 id="使用朴素贝叶斯过滤垃圾邮件">使用朴素贝叶斯过滤垃圾邮件</h2>

<h3 id="文本解析">文本解析</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">textParse</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">re</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">r'\W*'</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">_</span><span class="p">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">result</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">_</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">2</span><span class="p">]</span>
</code></pre></div></div>

<p>textParse函数将一个字符串文本拆分为单词列表，并将所有大写字母转换为小写，为了删除一些没有什么作用的单词，只返回拆分结果中长度大于2的单词。</p>

<h3 id="垃圾邮件测试">垃圾邮件测试</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">test_garbage_email</span><span class="p">():</span>
    <span class="n">doc_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">class_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">full_text</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># 读取文件
</span>    <span class="kn">import</span> <span class="nn">os</span>
    <span class="c1">## 读取正常邮件
</span>    <span class="n">base_dir_spam</span> <span class="o">=</span> <span class="s">'data/email/spam'</span>
    <span class="k">for</span> <span class="nb">file</span> <span class="ow">in</span> <span class="n">os</span><span class="p">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">base_dir_spam</span><span class="p">):</span>
        <span class="n">word_list</span> <span class="o">=</span> <span class="n">textParse</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">base_dir_spam</span><span class="o">+</span><span class="s">'/'</span><span class="o">+</span><span class="nb">file</span><span class="p">,</span><span class="s">'r'</span><span class="p">).</span><span class="n">read</span><span class="p">())</span>  <span class="c1"># 拆分文档内容
</span>        <span class="n">doc_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">word_list</span><span class="p">)</span>
        <span class="n">full_text</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">word_list</span><span class="p">)</span>
        <span class="n">class_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1">## 读取垃圾邮件
</span>    <span class="n">base_dir_ham</span> <span class="o">=</span> <span class="s">'data/email/ham'</span>
    <span class="k">for</span> <span class="nb">file</span> <span class="ow">in</span> <span class="n">os</span><span class="p">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">base_dir_ham</span><span class="p">):</span>
        <span class="s">"""fileName = base_dir_ham+'/'+file
        print(fileName)
        with open(fileName, '') as f:
            content = f.read()"""</span>
        <span class="n">word_list</span> <span class="o">=</span> <span class="n">textParse</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">base_dir_ham</span><span class="o">+</span><span class="s">'/'</span><span class="o">+</span><span class="nb">file</span><span class="p">,</span><span class="s">'r'</span><span class="p">).</span><span class="n">read</span><span class="p">())</span>  <span class="c1"># 查分文档内容
</span>        <span class="n">doc_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">word_list</span><span class="p">)</span>
        <span class="n">full_text</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">word_list</span><span class="p">)</span>
        <span class="n">class_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># 训练分类器
</span>    <span class="n">vocab_list</span> <span class="o">=</span> <span class="n">createVocabList</span><span class="p">(</span><span class="n">doc_list</span><span class="p">)</span>
    <span class="n">train_test_ratio</span> <span class="o">=</span> <span class="mf">0.8</span>  <span class="c1"># 训练测试集比例
</span>    <span class="n">training_set</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># 训练集
</span>    <span class="n">train_classes</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># 训练集标签
</span>    <span class="c1">#train_range = range(len(doc))
</span>    <span class="c1">## 随机构建训练集
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">train_test_ratio</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">doc_list</span><span class="p">))):</span>
        <span class="n">rand_index</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">doc_list</span><span class="p">))</span>
        <span class="n">training_set</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">doc_list</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="n">rand_index</span><span class="p">))</span>
        <span class="n">train_classes</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">class_list</span><span class="p">.</span><span class="n">pop</span><span class="p">(</span><span class="n">rand_index</span><span class="p">))</span>
    <span class="c1">## 构建测试集
</span>    <span class="n">test_set</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># 测试集
</span>    <span class="n">test_classes</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># 测试集标签
</span>    <span class="n">test_set</span> <span class="o">=</span> <span class="n">doc_list</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">test_classes</span> <span class="o">=</span> <span class="n">class_list</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="c1">## 将文档数据转化为矩阵
</span>    <span class="n">train_mat</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">content</span> <span class="ow">in</span> <span class="n">training_set</span><span class="p">:</span>
        <span class="n">train_mat</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">words2Vec_set</span><span class="p">(</span><span class="n">vocab_list</span><span class="p">,</span> <span class="n">content</span><span class="p">))</span>
    <span class="c1">## 训练分类器
</span>    <span class="n">p0_vec</span><span class="p">,</span> <span class="n">p1_vec</span><span class="p">,</span> <span class="n">pSpam</span> <span class="o">=</span> <span class="n">trainNB</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_mat</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_classes</span><span class="p">))</span>
    
    <span class="c1"># 测试分类器
</span>    <span class="n">error_count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">content</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test_set</span><span class="p">):</span>
        <span class="n">word_vec</span> <span class="o">=</span> <span class="n">words2Vec_set</span><span class="p">(</span><span class="n">vocab_list</span><span class="p">,</span> <span class="n">content</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">classifyNB</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">word_vec</span><span class="p">),</span> <span class="n">p0_vec</span><span class="p">,</span> <span class="n">p1_vec</span><span class="p">,</span> <span class="n">pSpam</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">result</span> <span class="o">!=</span> <span class="n">test_classes</span><span class="p">[</span><span class="n">index</span><span class="p">]:</span>
            <span class="n">error_count</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"the error rate is %f"</span> <span class="o">%</span> <span class="p">(</span><span class="n">error_count</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">test_set</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_garbage_email</span><span class="p">()</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>the error rate is 0.000000
</code></pre></div></div>

<h2 id="使用朴素贝叶斯分类器从个人广告中获取区域倾向">使用朴素贝叶斯分类器从个人广告中获取区域倾向</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">calcMostFreq</span><span class="p">(</span><span class="n">vocabList</span><span class="p">,</span> <span class="n">fullText</span><span class="p">):</span>
    <span class="s">"""
    统计单词出现次数
    vocabList: 词汇集合
    fullText: 所有文本
    """</span>
    <span class="n">freqDict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">vocabList</span><span class="p">:</span>
        <span class="n">freqDict</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">fullText</span><span class="p">.</span><span class="n">count</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
    <span class="n">freqDict</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">freqDict</span><span class="p">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>  <span class="c1"># 将单词出现次数按从大到小排列
</span>    <span class="k">return</span> <span class="n">freqDict</span><span class="p">[:</span><span class="mi">30</span><span class="p">]</span>  <span class="c1"># 返回出现次数最多的30个单词
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">localWords</span><span class="p">(</span><span class="n">feed1</span><span class="p">,</span><span class="n">feed0</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">feedparser</span>
    <span class="n">docList</span><span class="o">=</span><span class="p">[];</span> <span class="n">classList</span> <span class="o">=</span> <span class="p">[];</span> <span class="n">fullText</span> <span class="o">=</span><span class="p">[]</span>
    <span class="n">minLen</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">feed1</span><span class="p">[</span><span class="s">'entries'</span><span class="p">]),</span><span class="nb">len</span><span class="p">(</span><span class="n">feed0</span><span class="p">[</span><span class="s">'entries'</span><span class="p">]))</span>  <span class="c1"># 获取数据集长度
</span>    <span class="c1"># 数据处理
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">minLen</span><span class="p">):</span>
        <span class="n">wordList</span> <span class="o">=</span> <span class="n">textParse</span><span class="p">(</span><span class="n">feed1</span><span class="p">[</span><span class="s">'entries'</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s">'summary'</span><span class="p">])</span>
        <span class="n">docList</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">wordList</span><span class="p">)</span>
        <span class="n">fullText</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">wordList</span><span class="p">)</span>
        <span class="n">classList</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 将纽约设置为类别1
</span>        <span class="n">wordList</span> <span class="o">=</span> <span class="n">textParse</span><span class="p">(</span><span class="n">feed0</span><span class="p">[</span><span class="s">'entries'</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s">'summary'</span><span class="p">])</span>
        <span class="n">docList</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">wordList</span><span class="p">)</span>
        <span class="n">fullText</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">wordList</span><span class="p">)</span>
        <span class="n">classList</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># 将旧金山设置为类别0
</span>    <span class="n">vocabList</span> <span class="o">=</span> <span class="n">createVocabList</span><span class="p">(</span><span class="n">docList</span><span class="p">)</span>
    
    <span class="c1"># 去除出现次数最多的30个词语
</span>    <span class="n">top30Words</span> <span class="o">=</span> <span class="n">calcMostFreq</span><span class="p">(</span><span class="n">vocabList</span><span class="p">,</span><span class="n">fullText</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">pairW</span> <span class="ow">in</span> <span class="n">top30Words</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">pairW</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">in</span> <span class="n">vocabList</span><span class="p">:</span> <span class="n">vocabList</span><span class="p">.</span><span class="n">remove</span><span class="p">(</span><span class="n">pairW</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    
    <span class="c1"># 构建测试集
</span>    <span class="n">trainingSet</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">minLen</span><span class="p">);</span> <span class="n">testSet</span><span class="o">=</span><span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
        <span class="n">randIndex</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">trainingSet</span><span class="p">))</span>
        <span class="n">testSet</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">trainingSet</span><span class="p">[</span><span class="n">randIndex</span><span class="p">])</span>
        <span class="k">del</span><span class="p">(</span><span class="n">trainingSet</span><span class="p">[</span><span class="n">randIndex</span><span class="p">])</span>
    <span class="c1"># 构建训练集
</span>    <span class="n">trainMat</span><span class="o">=</span><span class="p">[];</span> <span class="n">trainClasses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">docIndex</span> <span class="ow">in</span> <span class="n">trainingSet</span><span class="p">:</span>
        <span class="n">trainMat</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">words2Vec_bag</span><span class="p">(</span><span class="n">vocabList</span><span class="p">,</span> <span class="n">docList</span><span class="p">[</span><span class="n">docIndex</span><span class="p">]))</span>
        <span class="n">trainClasses</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">classList</span><span class="p">[</span><span class="n">docIndex</span><span class="p">])</span>
    <span class="n">p0V</span><span class="p">,</span><span class="n">p1V</span><span class="p">,</span><span class="n">pSpam</span> <span class="o">=</span> <span class="n">trainNB</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">trainMat</span><span class="p">),</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">trainClasses</span><span class="p">))</span>
    
    <span class="c1"># 分类测试
</span>    <span class="n">errorCount</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">docIndex</span> <span class="ow">in</span> <span class="n">testSet</span><span class="p">:</span>
        <span class="n">wordVector</span> <span class="o">=</span> <span class="n">words2Vec_bag</span><span class="p">(</span><span class="n">vocabList</span><span class="p">,</span> <span class="n">docList</span><span class="p">[</span><span class="n">docIndex</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">classifyNB</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">wordVector</span><span class="p">),</span><span class="n">p0V</span><span class="p">,</span><span class="n">p1V</span><span class="p">,</span><span class="n">pSpam</span><span class="p">)</span> <span class="o">!=</span> <span class="n">classList</span><span class="p">[</span><span class="n">docIndex</span><span class="p">]:</span>
            <span class="n">errorCount</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'the error rate is: '</span><span class="p">,</span> <span class="n">errorCount</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">testSet</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">vocabList</span><span class="p">,</span><span class="n">p0V</span><span class="p">,</span><span class="n">p1V</span>
</code></pre></div></div>
:ET